{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Nets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set goals and introduce the framework\n",
    "\n",
    "Think of a model as a black box, we feed it an input and it creates an output. \n",
    "\n",
    "The input could be a number of factors.\n",
    "\n",
    "Before we can get comfortable with the output, we must train the model. It is a key part of ML.\n",
    "\n",
    "Once we have trained the model we can feed it with data and get an output.\n",
    "\n",
    "Training an algorithm involves four ingredients:\n",
    "- data\n",
    "- model\n",
    "- objective function\n",
    "- optimisation algorithm\n",
    "\n",
    "Data:<br>\n",
    "We must prepare a certain amount of data to train with.\n",
    "\n",
    "Model:<br>\n",
    "The simplest kind of model we could use is a linear model. This is just the tip of the iceberg. ML can help us create complex non-linear models that fit data better than a simple linear relationship.\n",
    "\n",
    "Obejective function: <br>\n",
    "We want the output to be as close to reality as possible. It estimates how correct the model outputs are on average. The entire ML framework boils down to optimising this function. \n",
    "\n",
    "Optimisation algorithm:<br>\n",
    "It consists of the mechanics through which we vary the parameters of the model to optimise the objective function.\n",
    "\n",
    "These are ingredients rather than steps, because this is iterative.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model\n",
    "\n",
    "In a ML setting we dont explicitly provide instructions to solve the problem, we just set our goals. The ML process is a trial and error game. A reasonable optimisation algorithm would not try all possible permutations, it would be smarter than that.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Types of ML\n",
    "\n",
    "There are 3 major types of machine learning:\n",
    "- supervised\n",
    "- unsupervised\n",
    "- reinforcement\n",
    "\n",
    "Supervised: <br>\n",
    "We provide the algorithm with inputs and their corresponding desired outputs. Based on this, it learns to produce outputs close to the ones that we are looking for.\n",
    "\n",
    "Unsupervised: <br>\n",
    "We provide inputs but there are no target outputs. This means we dont tell the algorithm what the answer is. We tell it to find dependents or patterns in the underlying data. This is useful for classification of data when you dont know what the categories are. It is a lot quicker than using supervised models which require people to classify items. Humans come in at the end of this models run and then classifies the resultant groups.\n",
    "\n",
    "Reinforcement: <br>\n",
    "We train a model to act in an environment based on rewards it receives, like training a pet. We can train a model to play Super Mario by rewarding it every time it progresses or scores points. \n",
    "\n",
    "This course focuses on supervised, which can be split into two types: \n",
    "- classification (provides outputs which are categories)\n",
    "- regression (provides outputs which are numerical types)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear model\n",
    "\n",
    "We want to make the algorithm find out a y, given an x.\n",
    "$ y = f(x)$\n",
    "\n",
    "We provide the algorithm with as many pairs of x and y's as possible and get it to follow the methodology.\n",
    "\n",
    "The linear model is the most simple model. In the linear universe $f(x) = xw +b$ where $x$ is the input, $w$ is the weight and $b$ is the bias(es).\n",
    "\n",
    "The linear model can be defined as a number of things:\n",
    "- $wx+b$\n",
    "- $xw+b$ (we will use this one)\n",
    "- $x^Tw+b$\n",
    "- $w^Tx+b$\n",
    "\n",
    "The goal of the ML algorithm would be to find such values for $w$ and $b$ so that the output of $xw+b$ is as close to the observed values as possible.\n",
    "\n",
    "E.g. predicting the price of an apartment. $x$ is the size, $y$ is the price. If you have values for $w$ and $b$, you can input any value of $x$ (size) and get a prediction for the price, based on the linear model.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear model - multiple inputs\n",
    "\n",
    "What if we had additional info, say location of apartment in relation to proximity to see. A better model would have the size of the apartment as well as the proximity to the beach. \n",
    "\n",
    "$size \\times size weight + proximity \\times proximity weight + bias$\n",
    "\n",
    "This is still $y = xw + b$.\n",
    "\n",
    "$x$ is a 1x2 vector and $w$ is a 2x1 vector. Multiplying the two gives a 1x1 scalar, per matrix mathematics. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple inputs and multiple outputs\n",
    "\n",
    "What if we are interested in predicting the price of purchasing an apartment, but also price we can get for renting it out.\n",
    "\n",
    "Out inputs are unchanged, size and proximity to beach. We have two outputs this time, and create two linear models.\n",
    "\n",
    "$price = size \\times size weight + proximity \\times proximity weight + bias$ <br>\n",
    "$rent = size \\times size weight + proximity \\times proximity weight + bias$\n",
    "\n",
    "$y_1 = x_1w_{11}+x_2w_{21}+b_1$ <br>\n",
    "$y_2 = x_1w_{12}+x_2w_{22}+b_2$\n",
    "\n",
    "There are two numbers in the indices for the weights. The first relates to the input, the second relates to the output. We have 2 outputs, 2 inputs, 4 weights and 2 biases. The number of weights depends on the inputs and the outputs. \n",
    "\n",
    "In general if we have M outputs and K inputs, the number of weights would be KxM and the number of biases is equal to M.\n",
    "\n",
    "$y_1y_2 = x_1x_2 \\times w_{11}w_{12}w_{21}w_{22} + b_1b_2$\n",
    "\n",
    "This example only had 2 observations. It could be extended to N observations, where the output is an NxM matrix, where M is number of output variables. The input matrix would be NxK, where K would be number of input variables. The weights matrix remains the same at KxM as weights dont change based on number of observations. This is also true for biases which would be 1xM. This last bit is important as it shows us that we can feed as much data into our model as we want to without affecting it, as each model is determined solely by its weights and biases. \n",
    "\n",
    "In ML, we vary only the weights and the biases but the logic of the model remains the same.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graphical representation of neural networks\n",
    "\n",
    "Linear classifiers are useful if the data is linearly separable, i.e. the data split makes sense when separated by a straight line.\n",
    "\n",
    "This is not always the case though.\n",
    "\n",
    "What if you have several categories and you cant fit a straight line through them? In these instances, we must use non-linear models.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective function\n",
    "\n",
    "The objective function is the measure used to evaluate how well the model's outputs match the desired correct values.\n",
    "\n",
    "Objective functions are generally split into two types:\n",
    "- loss functions\n",
    "- reward functions\n",
    "\n",
    "Loss functions are also called cost functions. The lower the loss function, the higher the level of accuracy for the model. Most often we work with these. Typically a loss function measures the error of prediction and a low score here is better. These are typically used in supervised learning.\n",
    "\n",
    "Reward functions are the opposite. The higher the reward function, the higher the accuracy of the model. These are typically used in reinforcement learning. \n",
    "\n",
    "This course looks at loss functions most, due to their prevalence in supervised learning.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Types of loss functions\n",
    "\n",
    "Two common types of loss functions:\n",
    "- L2-norm (used in regression)\n",
    "- Cross-entropy (used in classification)\n",
    "\n",
    "The following is true for all models, irrespective of their linearity.\n",
    "\n",
    "The target, T, is the desired value at which we are aiming. Generally we want our output to be as close as possible to T.\n",
    "\n",
    "### L2-norm\n",
    "\n",
    "Method for calculating L2-norm is the OLS (ordinary least squares) method commonly used in statistics.\n",
    "\n",
    "$ L2norm = \\sum_i(y_i-t_i)^2$\n",
    "\n",
    "'Norm' comes from the fact it is the vector norm, or Euclidian distance of the outputs and the targets.\n",
    "\n",
    "The lower the error, the lower the loss.\n",
    "\n",
    "### Cross-entropy loss\n",
    "\n",
    "Cross-entropy = $L(y,t) = -\\sum_it_i\\ln_i$\n",
    "\n",
    "Imagine you had an image classifier that is classifying images as a Cat, a Dog or a Horse.\n",
    "\n",
    "It would do so by giving each image a score where the targets (t) for each are:\n",
    "- [1,0,0) for a cat\n",
    "- [0,1,0] for a dog\n",
    "- [0,0,1] for a horse\n",
    "\n",
    "Given output scores (y) as:\n",
    "- [0.4,0.4,0.2] for a dog\n",
    "- [0.1,0.2,0.7] for a horse\n",
    "\n",
    "You can use the cross-entropy formula to find out an accuracy score, remembering that the lower number is better:\n",
    "- $L(y,t) = -0\\times\\ln0.4-1\\times\\ln0.4-0\\times\\ln0.2 = 0.92$ for the dog\n",
    "- $L(y,t) = -0\\times\\ln0.1-0\\times\\ln0.2-1\\times\\ln0.7 = 0.36$ for the horse\n",
    "\n",
    "The model is not sure that the first image is a dog or a cat, but it is quite sure that the second image is a horse. \n",
    "\n",
    "Given that the target scores have a number of zeros in them, you can simplify both calculations as follows:\n",
    "- $L(y,t) = -1\\times\\ln0.4$\n",
    "- $L(y,t) = -1\\times\\ln0.7$\n",
    "\n",
    "Most regression and classification models are solved using these functions. There are others that are used and in general, any function that holds the basic property *'higher for worse results, lower for better results'* can be a loss function. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient descent\n",
    "\n",
    "The simplest and most fundamental optimisation algorithm is the Gradient Descent.\n",
    "\n",
    "The gradient is the multivariate generalisation of the derivative concept. \n",
    "\n",
    "$f(x) = fx^2+3x-3$ \n",
    "\n",
    "Goal: find the minimum of this function.\n",
    "\n",
    "The first step is to find the first derivative of the funciton.\n",
    "\n",
    "$f'(x) = 10x+3$\n",
    "\n",
    "The second step is to choose any arbitrary number (e.g. $x_0=4$) and then calculate a different number ($x_1=?$) using the update rule:\n",
    "\n",
    "$x_{i+1}=x_i-\\eta f'(x_i)$\n",
    "\n",
    "$x_1=4-\\eta[10\\times4+3] = 4- \\eta_43$\n",
    "\n",
    "$\\eta$(eta) is the learning rate. The rate at which the ML algorithm forgets old beliefs for new ones.\n",
    "\n",
    "Using the update rule we can find $x_1, x_2, x_3, \\dots, x_n$ \n",
    "\n",
    "When the values stop updating using that function, we know the minimum is reached. The first derivative of the function is zero:\n",
    "\n",
    "$\\eta f'(x_i) = 0$\n",
    "\n",
    "Eventually it will become: \n",
    "\n",
    "$x_{i+1} = x_i$\n",
    "\n",
    "\n",
    "If eta is too small, it will take too long to get to the minimum point. If it is too large, it will never reach the minimum and will oscillate at a higher value. \n",
    "\n",
    "Generally, we want the learning rate to be high enough so we can reach the closest minimum in a rational amount of time. We want it to be low enough so we dont oscillate around the minimum.\n",
    "\n",
    "Several key takeaways:\n",
    "- we can find the minimum by trial and error using gradient descent\n",
    "- there is an update rule that allows us to cherry pick the trial and reach the minimum faster\n",
    "- learning rate should be high enough so we dont iterate forever, but low enough so we dont oscillate forever\n",
    "- we should stop updating once we've converged\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## n-Parameter Gradient Descent\n",
    "\n",
    "Consider linear model we have discussed so far:\n",
    "\n",
    "$xw+b=y$ -> model\n",
    "\n",
    "Now each output $y_i$ can be represented using the linear model equation, where the input is just the corresponding $x_i$. The weights and the bias remain unchanged.\n",
    "\n",
    "Using the apartment example, $y_i$ would be the price of a single apartment. The corresponding $x_i$ is information we have about that apartment.\n",
    "\n",
    "$x_iw+b=y_i$ -> single observation\n",
    "\n",
    "Therefore, the output $y_i$ is a scalar and is equal to the corresponding $x_i \\times w + b$.\n",
    "\n",
    "We are interested in the target $t_i$ and this is what we will compare the output $y_i$ against.\n",
    "\n",
    "We need to choose our loss function, denoted as $L(y,t)$.\n",
    "\n",
    "$L(y,t)$ -> loss <br>\n",
    "$C(y,t)$ -> cost <br>\n",
    "$E(y,t)$ -> error <br>\n",
    "\n",
    "We are going to look into a regression example, so lets choose the L2-norm function (modified slightly with the /2).\n",
    "\n",
    "loss: $L(y,t) = \\frac{L2norm}{2} = \\frac{\\sum_i(y_i-t_i)^2}{2}$\n",
    "\n",
    "A division by the constant of 2 does not change the loss function as it holds the basic property of being higher for worse results and lower for better results.\n",
    "\n",
    "To perform the gradient decent we need old beliefs which will be updated in each step.\n",
    "\n",
    "The update rule: $x_{i+1} = x_i-\\eta f'(x_i)$\n",
    "\n",
    "Becomes: $w_{i+1} = w_i - \\eta \\nabla_wL(y,t)$ for weights\n",
    "\n",
    "And: $b_{i+1} = b_i - \\eta \\nabla_bL(y,t)$ for biases\n",
    "\n",
    "We want to minimise the loss function by varying the weights and the biases. This means we are typing to optimise the loss function regarding w and b.\n",
    "\n",
    "$\\nabla_wL = \\sum_i\\nabla_w\\frac{1}{2}(y_i-t_i)^2 =$\n",
    "\n",
    "$\\nabla_wL = \\sum_ix_i(y_i-t_i) =$\n",
    "\n",
    "$\\nabla_wL = \\sum_ix_i\\delta_i$\n",
    "\n",
    "$\\nabla_bL = \\sum_i\\delta_i$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "udemyDS",
   "language": "python",
   "name": "udemyds"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outlining the model\n",
    "\n",
    "\n",
    "We have 10 inputs and 2 outputs, as there are only 2 possibilities.\n",
    "\n",
    "We will build 2 hidden layers with 50 hidden units. This is easy to change later, but is a good starting point. \n",
    "\n",
    "## Import relevant libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "npz = np.load('Audiobooks_data_train.npz')\n",
    "\n",
    "train_inputs = npz['inputs'].astype(np.float)\n",
    "train_targets = npz['targets'].astype(np.int)\n",
    "\n",
    "npz = np.load('Audiobooks_data_validation.npz')\n",
    "validation_inputs, validation_targets = npz['inputs'].astype(np.float),npz['targets'].astype(np.int)\n",
    "\n",
    "npz = np.load('Audiobooks_data_test.npz')\n",
    "test_inputs,test_targets = npz['inputs'].astype(np.float),npz['targets'].astype(np.int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "Copied code from MNIST lecture... it is the same with parameter changes and removal of the flattening element as we already did preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "36/36 - 0s - loss: 0.5477 - accuracy: 0.7678 - val_loss: 0.4202 - val_accuracy: 0.8770\n",
      "Epoch 2/100\n",
      "36/36 - 0s - loss: 0.3558 - accuracy: 0.8768 - val_loss: 0.3120 - val_accuracy: 0.8837\n",
      "Epoch 3/100\n",
      "36/36 - 0s - loss: 0.3095 - accuracy: 0.8824 - val_loss: 0.2842 - val_accuracy: 0.8993\n",
      "Epoch 4/100\n",
      "36/36 - 0s - loss: 0.2908 - accuracy: 0.8894 - val_loss: 0.2806 - val_accuracy: 0.8971\n",
      "Epoch 5/100\n",
      "36/36 - 0s - loss: 0.2813 - accuracy: 0.8927 - val_loss: 0.2623 - val_accuracy: 0.9060\n",
      "Epoch 6/100\n",
      "36/36 - 0s - loss: 0.2700 - accuracy: 0.8944 - val_loss: 0.2541 - val_accuracy: 0.9083\n",
      "Epoch 7/100\n",
      "36/36 - 0s - loss: 0.2633 - accuracy: 0.8997 - val_loss: 0.2506 - val_accuracy: 0.9150\n",
      "Epoch 8/100\n",
      "36/36 - 0s - loss: 0.2572 - accuracy: 0.9003 - val_loss: 0.2433 - val_accuracy: 0.9172\n",
      "Epoch 9/100\n",
      "36/36 - 0s - loss: 0.2530 - accuracy: 0.9053 - val_loss: 0.2374 - val_accuracy: 0.9195\n",
      "Epoch 10/100\n",
      "36/36 - 0s - loss: 0.2497 - accuracy: 0.9039 - val_loss: 0.2521 - val_accuracy: 0.9083\n",
      "Epoch 11/100\n",
      "36/36 - 0s - loss: 0.2493 - accuracy: 0.9050 - val_loss: 0.2450 - val_accuracy: 0.9105\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x148050860>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_size = 10\n",
    "output_size = 2\n",
    "hidden_layer_size = 50\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(hidden_layer_size,activation='relu'), # activation function chosen because it is known to be good at this problem\n",
    "    tf.keras.layers.Dense(hidden_layer_size,activation='relu'),\n",
    "    tf.keras.layers.Dense(output_size,activation='softmax') # output layer for this problem must turn outputs into probabilities, which softmax does.    \n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "batch_size = 100\n",
    "max_epochs = 100\n",
    "\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(patience=2)\n",
    "\n",
    "model.fit(train_inputs,\n",
    "          train_targets,\n",
    "          batch_size = batch_size,\n",
    "          epochs=max_epochs,\n",
    "          callbacks=[early_stopping],\n",
    "          validation_data=(validation_inputs,\n",
    "                           validation_targets),\n",
    "          verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the original run, with 100 batch size and 100 epochs, the model looks like it has overfitted because the loss function is constantly reducing, but the val_loss is sometimes going up and sometimes going down. \n",
    "\n",
    "We probably need to set an early stopping procedure to fix this.\n",
    "\n",
    "The early stopping variable is now in the code. By default, the Early Stopping object will monitor the validation loss and stop the training process the first time the validation loss starts increasing.\n",
    "\n",
    "With the early stopping, there are only 7 epochs out of 100 before it stops. Sometimes you can allow 1 or 2 increases in validation losses to occur, in which case you can change the input to the early stopping object. The variable it takes is called patience, which lets us decide how many consecutive increases it tolerates.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this model, we started out with a list of customers with 50% chance of guessing if they will buy another audiobook. With the model, we can predict with 90% accuracy whether a customer will buy or not buy another book.\n",
    "\n",
    "## Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 1ms/step - loss: 0.2637 - accuracy: 0.9062\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(test_inputs, test_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test loss: 0.26. Test accuracy: 90.62%\n"
     ]
    }
   ],
   "source": [
    "print('\\nTest loss: {0:.2f}. Test accuracy: {1:.2f}%'.format(test_loss,test_accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final accuracy of the model is close to the validation accuracy. Great"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "udemyDS",
   "language": "python",
   "name": "udemyds"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
